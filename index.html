<!DOCTYPE html>
<html>

<head>
    <link rel="stylesheet" href="style.css">
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
    <title>Temario</title>
</head>

<body>
    <center>
        <h1>Tema 1</h1>
    </center>
    <center>
        <h2>Estadistica descriptiva</h2>
    </center>
    <img src="https://www.questionpro.com/blog/wp-content/uploads/2021/05/1711-Portada-estadistica-descriptiva.jpg" />

    <!-- Tema 1 -->
    <ul>
        <li>
            <h4>1.1 Conceptos b√°sicos de estad√≠stica.</h4>
            <ul>
                <li><b>Definici√≥n de Estad√≠stica:</b>
                    La estad√≠stica es la ciencia que estudia c√≥mo recopilar, organizar, analizar e interpretar datos
                    para tomar decisiones informadas. Se divide en dos ramas principales:
                    <ul>
                        <li><b>Estad√≠stica descriptiva:</b> Se encarga de resumir y describir las caracter√≠sticas de un
                            conjunto de datos.</li>
                        <li><b>Estad√≠stica inferencial:</b> Utiliza una muestra de datos para hacer inferencias o
                            generalizaciones sobre una poblaci√≥n m√°s grande.</li>
                    </ul>
                </li>

                <br>

                <li><b>Teor√≠a de Decisi√≥n:</b>
                    La teor√≠a de decisi√≥n se enfoca en la toma de decisiones √≥ptimas bajo condiciones de incertidumbre.
                    Involucra la identificaci√≥n de diferentes alternativas, la evaluaci√≥n de sus posibles resultados y
                    la selecci√≥n de la opci√≥n que maximiza los beneficios o minimiza los costos.
                    <ul>
                        <li><b>Decisor:</b> Persona o entidad que toma la decisi√≥n.</li>
                        <li><b>Alternativas:</b> Opciones disponibles entre las cuales se puede elegir.</li>
                        <li><b>Estados de la naturaleza:</b> Condiciones o eventos que pueden ocurrir y que afectan el
                            resultado de la decisi√≥n.</li>
                        <li><b>Pagos o recompensas:</b> Consecuencias asociadas a cada combinaci√≥n de alternativa y
                            estado de la naturaleza.</li>
                        <li><b>Criterio de decisi√≥n:</b> Regla o principio usado para seleccionar la mejor alternativa
                            (por ejemplo, maximizaci√≥n de la utilidad esperada).</li>
                    </ul>
                </li>

                <br>

                <li><b>Poblaci√≥n:</b>
                    En estad√≠stica, la poblaci√≥n se refiere al conjunto completo de individuos, elementos, o eventos que
                    poseen alguna caracter√≠stica com√∫n y sobre la cual se desea realizar inferencias. Puede ser finita
                    (por ejemplo, todos los estudiantes de una escuela) o infinita (por ejemplo, todos los posibles
                    resultados de lanzar un dado).
                </li>

                <br>

                <li><b>Muestra Aleatoria:</b>
                    Una muestra aleatoria es un subconjunto de la poblaci√≥n seleccionado de tal manera que cada
                    individuo tiene una probabilidad conocida y no nula de ser incluido. Las muestras aleatorias son
                    fundamentales en estad√≠stica porque permiten hacer inferencias sobre la poblaci√≥n con un cierto
                    nivel de confianza.
                    <ul>
                        <li><b>Muestreo aleatorio simple:</b> Cada miembro de la poblaci√≥n tiene la misma probabilidad
                            de ser seleccionado.</li>
                        <li><b>Muestreo sistem√°tico:</b> Se selecciona cada √©simo individuo de una lista ordenada de la
                            poblaci√≥n.</li>
                        <li><b>Muestreo estratificado:</b> La poblaci√≥n se divide en subgrupos homog√©neos (estratos) y
                            se selecciona una muestra aleatoria de cada estrato.</li>
                        <li><b>Muestreo por conglomerados:</b> La poblaci√≥n se divide en grupos heterog√©neos
                            (conglomerados) y se selecciona una muestra aleatoria de estos conglomerados.</li>
                    </ul>
                </li>
                <br>

                <li><b>Par√°metros Aleatorios:</b>
                    Los par√°metros aleatorios son caracter√≠sticas num√©ricas de una poblaci√≥n que se desconocen y que se
                    estiman a partir de muestras. Ejemplos de par√°metros incluyen:
                    <ul>
                        <li><b>Media (Œº):</b> Valor promedio de la poblaci√≥n.</li>
                        <li><b>Varianza (œÉ¬≤):</b> Medida de la dispersi√≥n de los valores de la poblaci√≥n respecto a la
                            media.</li>
                        <li><b>Proporci√≥n (p):</b> Fracci√≥n de la poblaci√≥n que posee una determinada caracter√≠stica.
                        </li>
                    </ul>
                    Estos par√°metros se contrastan con las <b>estad√≠sticas muestrales</b>, que son valores calculados a
                    partir de una muestra y utilizados para estimar los par√°metros poblacionales. Por ejemplo, la media
                    muestral se usa para estimar la media poblacional (Œº).
                </li>
            </ul>
        </li>

        <li>
            <h4>1.2 Descripci√≥n de datos.</h4>
            <ul>
                <li><b>Datos agrupados y no agrupados:</b>
                    <ul>
                        <li><b>Datos no agrupados:</b> Son datos que se presentan en su forma original sin ninguna
                            organizaci√≥n. Por ejemplo, las alturas individuales de un grupo de estudiantes.</li>
                        <li><b>Datos agrupados:</b> Son datos organizados en tablas de frecuencias. Por ejemplo, las
                            alturas de un grupo de estudiantes organizadas en intervalos de altura.</li>
                    </ul>
                </li>

                <br>

                <li><b>Frecuencia de clase:</b>
                    Es el n√∫mero de observaciones que caen dentro de un intervalo de clase espec√≠fico en una
                    distribuci√≥n de frecuencias.
                </li>

                <br>

                <li><b>Frecuencia relativa:</b>
                    Es la proporci√≥n o fracci√≥n de observaciones que pertenecen a una clase en particular. Se calcula
                    dividiendo la frecuencia de clase por el n√∫mero total de observaciones.
                </li>

                <br>

                <li><b>Punto medio:</b>
                    Es el valor central de un intervalo de clase. Se calcula sumando los l√≠mites inferior y superior del
                    intervalo y dividiendo por dos.
                </li>

                <br>

                <li><b>L√≠mites:</b>
                    Los l√≠mites de clase son los valores que marcan el inicio y el final de un intervalo de clase.
                    Existen dos tipos:
                    <ul>
                        <li><b>L√≠mites reales:</b> Incluyen todos los valores posibles dentro del intervalo,
                            considerando cualquier posible valor decimal o fraccionario.</li>
                        <li><b>L√≠mites aparentes:</b> Son los valores que se presentan como los bordes del intervalo y
                            no consideran los decimales o fraccionarios.</li>
                    </ul>
                </li>
            </ul>
        </li>


        <li>
            <h4>1.3 Medidas de tendencia central y de dispersi√≥n.</h4>
            <ul>
                <li><b>Media aritm√©tica:</b>
                    Es el promedio de un conjunto de datos y se calcula sumando todos los valores y dividiendo por el
                    n√∫mero total de observaciones.
                </li>

                <br>

                <li><b>Media geom√©trica:</b>
                    Es la ra√≠z en√©sima del producto de n valores, √∫til especialmente para datos que representan tasas de
                    crecimiento.
                </li>

                <br>

                <li><b>Media ponderada:</b>
                    Es similar a la media aritm√©tica pero asignando diferentes pesos a diferentes valores. Se calcula
                    multiplicando cada valor por su peso, sumando estos productos y dividiendo por la suma de los pesos.
                </li>

                <br>

                <li><b>Mediana:</b>
                    Es el valor que divide un conjunto de datos ordenados en dos partes iguales. Si el n√∫mero de
                    observaciones es impar, la mediana es el valor central; si es par, es el promedio de los dos valores
                    centrales.
                </li>

                <br>

                <li><b>Moda:</b>
                    Es el valor o valores que aparecen con mayor frecuencia en un conjunto de datos. Un conjunto de
                    datos puede tener una moda (unimodal), dos modas (bimodal) o m√°s (multimodal).
                </li>

                <br>

                <li><b>Medidas de dispersi√≥n:</b>
                    Las medidas de dispersi√≥n describen la variabilidad o dispersi√≥n de los datos respecto a la
                    tendencia central.
                    <ul>
                        <li><b>Varianza (œÉ¬≤):</b>
                            Es la media de los cuadrados de las desviaciones de los valores respecto a la media. Indica
                            cu√°nto var√≠an los datos respecto a la media.
                        </li>
                        <li><b>Desviaci√≥n est√°ndar (œÉ):</b>
                            Es la ra√≠z cuadrada de la varianza y proporciona una medida de dispersi√≥n en las mismas
                            unidades que los datos originales.
                        </li>
                        <li><b>Desviaci√≥n media:</b>
                            Es la media de las desviaciones absolutas respecto a la media.
                        </li>
                        <li><b>Desviaci√≥n mediana:</b>
                            Es la mediana de las desviaciones absolutas respecto a la mediana del conjunto de datos.
                        </li>
                        <li><b>Rango:</b>
                            Es la diferencia entre el valor m√°ximo y el valor m√≠nimo de un conjunto de datos.
                            Proporciona una medida sencilla de la dispersi√≥n.
                        </li>
                    </ul>
                </li>
            </ul>
        </li>

        <li>
            <h4>1.4 Par√°metros para datos agrupados.</h4>
            <ul>
                <li>Estos par√°metros permiten resumir y caracterizar adecuadamente
                    un conjunto de datos cuando estos se presentan de manera agrupada.</li>
            </ul>
        </li>

        <li>
            <h4>1.5 Distribuci√≥n de frecuencias.</h4>
            <ul>
                <li>La distribuci√≥n de frecuencias permite analizar la forma,
                    dispersi√≥n y tendencia central de un conjunto de datos,
                    facilitando su interpretaci√≥n y comprensi√≥n.</li>
            </ul>
        </li>

        <li>
            <h4>1.6 T√©cnicas de agrupaci√≥n de datos.</h4>
            <ul>
                <li>Estas t√©cnicas permiten estructurar adecuadamente
                    los datos, facilitando su an√°lisis, visualizaci√≥n e
                    interpretaci√≥n estad√≠stica.</li>
            </ul>
        </li>

        <li>
            <h4>1.7 T√©cnicas de muestreo.</h4>
            <ul>
                <li>Estas t√©cnicas permiten obtener muestras representativas de la
                    poblaci√≥n, de acuerdo a los objetivos y caracter√≠sticas del estudio.
                </li>
            </ul>
        </li>
    </ul>
    <b>Ejemplos en el siguiente link:</b>

    <a href="https://nbviewer.org/github/imac22/Frecuencias/blob/685d5fdfe6a3038fe4dfe63c0c09bedb8ac41843/numeros.ipynb">Aqu√≠</a>

    <!-- Tema 2 -->
    <center>
        <h1>Tema 2</h1>
    </center>
    <center>
        <h2>Fundamentos de la Teor√≠a de Probabilidad.</h2>
    </center>
    <img src="https://www.esan.edu.pe/images/blog/2016/10/10/probabilidades-principal.jpg" />

    <ul>
        <li>
            <h4>2.1 Conceptos b√°sicos de estad√≠stica.</h4>
            <ul>
                <li>Las t√©cnicas de conteo son m√©todos utilizados en combinatoria y probabilidad para contar el n√∫mero
                    de formas en que se pueden realizar ciertas acciones o formar conjuntos. A continuaci√≥n, se
                    describen algunas t√©cnicas de conteo fundamentales:</li>

                <br>

                <li><b>2.1.1 Principio aditivo.</b>
                    El principio aditivo se utiliza cuando se cuenta el n√∫mero total de elementos en una uni√≥n de
                    conjuntos disjuntos. Si tenemos varios conjuntos que no tienen elementos en com√∫n, el n√∫mero total
                    de elementos es la suma de los elementos de cada conjunto.
                </li>

                <br>

                <b>Ejemplo</b>
                Si hay 3 maneras de elegir un objeto del conjunto A y 4 maneras de elegir un objeto del conjunto B, y A
                y B son disjuntos, entonces hay 3 + 4 = 7 maneras de elegir un objeto de A o B.

                <br>
                <br>

                <li><b> 2.1.2 Principio multiplicativo:</b>
                    El principio multiplicativo se utiliza cuando se cuenta el n√∫mero total de formas en que se pueden
                    realizar varias acciones secuenciales. Si una acci√≥n se puede realizar de ùëõ maneras y una segunda
                    acci√≥n se puede realizar de ùëö maneras, entonces hay ùëõ √ó ùëö maneras de realizar ambas acciones.
                </li>

                <br>

                <b>Ejemplo</b>
                Si hay 3 maneras de elegir un primer objeto y 4 maneras de elegir un segundo objeto, entonces hay 3 √ó 4
                = 12 maneras de elegir ambos objetos.

                <br>
                <br>

                <li><b>2.1.3 Notaci√≥n Factorial:</b>
                    La notaci√≥n factorial (denotada como ùëõ!) se utiliza para contar el n√∫mero de maneras en que se
                    pueden ordenar ùëõ elementos distintos.
                </li>

                <br>

                <b>Formula</b>
                <p>\[n! = n √ó (n ‚àí 1) √ó (n ‚àí 2) √ó ‚ãØ √ó 1\]</p>

                <b>Ejemplo</b>
                <p>\[5! = 5 √ó 4 √ó 3 √ó 2 √ó 1 = 120\]</p>

                <br>
                <br>

                <li><b> 2.1.4 Permutaciones:</b>
                    Las permutaciones son arreglos ordenados de un conjunto de elementos. El n√∫mero de permutaciones de
                    ùëõ elementos es ùëõ!. Si se seleccionan ùëü elementos de un conjunto de ùëõ elementos para formar
                    permutaciones, se utiliza la notaci√≥n ùëÉ(ùëõ,ùëü).
                </li>

                <br>

                <b>Formula</b>
                <p>\[ P(n, r) = \frac{n!}{(n-r)!} \]</p>

                <b>Ejemplo</b>
                El n√∫mero de maneras de ordenar 3 elementos de un conjunto de 5 elementos es: \[ùëÉ(5,3) = \frac{5!}{(5 ‚àí
                3)!} = \frac{5 √ó 4 √ó 3 √ó 2 √ó 1} {2 √ó 1} = 60\]

                <br>
                <br>

                <li><b> 2.1.5 Combinaciones:</b>
                    Las combinaciones son selecciones no ordenadas de elementos de un conjunto. El n√∫mero de
                    combinaciones de ùëõ elementos tomados ùëü a la vez se denota como ùê∂(ùëõ,ùëü) o (ùëõ / ùëü).
                </li>

                <br>

                <b>Formula</b>
                <p>\[C(n,r) = \frac{n}{r} = \frac{n!}{r!(n‚àír)!}\]</p>

                <b>Ejemplo</b>
                El n√∫mero de maneras de elegir 3 elementos de un conjunto de 5 elementos es:\[C(5,3) =
                \frac{5!}{3!(5-3)!} = \frac{5 \times 4 \times 3 \times 2 \times 1}{3 \times 2 \times 1 \times 2 \times
                1} = 10\]

                <br>
                <br>

                <li><b> 2.1.6 Diagrama de √Årbol:</b>
                    Un diagrama de √°rbol es una representaci√≥n gr√°fica que se utiliza para visualizar y contar el n√∫mero
                    de resultados posibles de un evento o serie de eventos.
                </li>

                <br>

                <b>Ejemplo</b>
                Si se lanza una moneda y luego se lanza un dado, un diagrama de √°rbol puede mostrar todas las
                combinaciones posibles de resultados (cara/cruz seguido de 1, 2, 3, 4, 5, 6).

                <br>

                <br>

                <li><b> 2.1.7 Teorema del Binomio:</b>
                    El teorema del binomio proporciona una f√≥rmula para expandir una potencia de un binomio. Se utiliza
                    en combinatoria para contar combinaciones de elementos con repetici√≥n.
                </li>

                <br>

                <li>
                    <h4>2.1 Conceptos b√°sicos de estad√≠stica.</h4>
                    <ul>
                        <li>Las t√©cnicas de conteo son m√©todos utilizados en combinatoria y probabilidad para contar el
                            n√∫mero de formas en que se pueden realizar ciertas acciones o formar conjuntos. A
                            continuaci√≥n, se describen algunas t√©cnicas de conteo fundamentales:</li>
                        <ul>
                            <li><strong>Permutaciones</strong>: La cantidad de maneras en que se pueden ordenar un
                                conjunto de objetos.</li>
                            <li><strong>Combinaciones</strong>: La cantidad de maneras en que se pueden seleccionar
                                objetos de un conjunto, sin importar el orden.</li>
                            <li><strong>Principio de la multiplicaci√≥n</strong>: Si una tarea puede realizarse de \( n
                                \) maneras y otra tarea puede realizarse de \( m \) maneras, entonces ambas tareas
                                pueden realizarse de \( n \times m \) maneras.</li>
                            <li><strong>Principio de la adici√≥n</strong>: Si un evento puede ocurrir de \( n \) maneras
                                y otro evento puede ocurrir de \( m \) maneras, y estos eventos no pueden ocurrir
                                simult√°neamente, entonces el n√∫mero total de maneras en que uno de los eventos puede
                                ocurrir es \( n + m \).</li>
                        </ul>
                    </ul>
                </li>
                <li>
                    <h4>2.2 Teor√≠a elemental de probabilidad.</h4>
                    <ul>
                        <li>La teor√≠a elemental de probabilidad es una rama de las matem√°ticas que estudia los fen√≥menos
                            aleatorios y los eventos inciertos. Sus conceptos b√°sicos incluyen:</li>
                        <ul>
                            <li><strong>Experimento aleatorio</strong>: Un proceso que produce un resultado incierto.
                            </li>
                            <li><strong>Evento</strong>: Un subconjunto de posibles resultados de un experimento
                                aleatorio.</li>
                            <li><strong>Probabilidad</strong>: Una medida cuantitativa de la incertidumbre asociada con
                                un evento.</li>
                        </ul>
                    </ul>
                </li>
                <li>
                    <h4>2.3 Probabilidad de Eventos.</h4>
                    <ul>
                        <li><strong>Definici√≥n de espacio muestral</strong>: El conjunto de todos los posibles
                            resultados de un experimento aleatorio. Por ejemplo, al lanzar un dado, el espacio muestral
                            es {1, 2, 3, 4, 5, 6}.</li>
                        <li><strong>Definici√≥n de evento</strong>: Cualquier subconjunto del espacio muestral. Por
                            ejemplo, obtener un n√∫mero par al lanzar un dado puede ser el evento {2, 4, 6}.</li>
                        <li><strong>Simbolog√≠a</strong>:</li>
                        <ul>
                            <li><strong>P(E)</strong>: La probabilidad de que ocurra el evento E.</li>
                            <li><strong>E'</strong>: El complemento de E, que representa todos los resultados en el
                                espacio muestral que no est√°n en E.</li>
                        </ul>
                        <li><strong>Uni√≥n e intersecci√≥n</strong>:</li>
                        <ul>
                            <li><strong>Uni√≥n (E ‚à™ F)</strong>: Un evento que ocurre si ocurre E, F, o ambos.</li>
                            <li><strong>Intersecci√≥n (E ‚à© F)</strong>: Un evento que ocurre si ocurren tanto E como F.
                            </li>
                        </ul>
                        <li><strong>Diagramas de Venn</strong>: Los diagramas de Venn son una herramienta gr√°fica para
                            representar visualmente la relaci√≥n entre diferentes eventos en un espacio muestral.</li>
                    </ul>
                </li>
                <li>
                    <h4>2.4 Probabilidad con T√©cnicas de Conteo.</h4>
                    <ul>
                        <li><strong>Axiomas de probabilidad</strong>:</li>
                        <ul>
                            <li>La probabilidad de un evento es un n√∫mero no negativo: \( P(E) \geq 0 \).</li>
                            <li>La probabilidad del espacio muestral completo es 1: \( P(S) = 1 \).</li>
                            <li>Si dos eventos E y F son mutuamente excluyentes (es decir, \( E \cap F = \emptyset \)),
                                entonces \( P(E \cup F) = P(E) + P(F) \).</li>
                        </ul>
                        <li><strong>Teoremas de probabilidad</strong>:</li>
                        <ul>
                            <li>Teorema de la probabilidad total: Si \( \{A_1, A_2, ..., A_n\} \) es una partici√≥n del
                                espacio muestral S, entonces \( P(B) = \sum_{i=1}^n P(B \cap A_i) \).</li>
                        </ul>
                    </ul>
                </li>
                <li>
                    <h4>2.5 Probabilidad condicional.</h4>
                    <ul>
                        <li><strong>Dependiente e Independiente</strong>:</li>
                        <ul>
                            <li>Probabilidad condicional: La probabilidad de un evento A dado que otro evento B ha
                                ocurrido, denotada como \( P(A|B) \).</li>
                            <li>Eventos dependientes: Dos eventos A y B son dependientes si la ocurrencia de uno afecta
                                la probabilidad del otro.</li>
                            <li>Eventos independientes: Dos eventos A y B son independientes si \( P(A \cap B) =
                                P(A)P(B) \).</li>
                        </ul>
                    </ul>
                </li>
                <li>
                    <h4>2.6 Ley multiplicativa.</h4>
                    <ul>
                        <li>La ley multiplicativa para eventos independientes establece que \( P(A \cap B) = P(A)P(B)
                            \).</li>
                    </ul>
                </li>
                <li>
                    <h4>2.7 Eventos independientes: Regla de Bayes.</h4>
                    <ul>
                        <li>Regla de Bayes: Una f√≥rmula que describe la probabilidad de un evento, basada en el
                            conocimiento previo de condiciones que podr√≠an estar relacionadas con el evento. Se expresa
                            como:</li>
                        <li>\[ P(A|B) = \frac{P(B|A)P(A)}{P(B)} \]</li>
                        <li>Esta regla es fundamental en la estad√≠stica y en muchas aplicaciones de la teor√≠a de
                            probabilidad.</li>
                    </ul>
                </li>
            </ul>
            <b>Ejemplos en el siguiente link:</b>

            <a href="https://nbviewer.org/github/EduardoGomezTics/Problemas_Equipo/blob/045688584291a323a6292a43198e4dd624f7ca24/Main.ipynb">Aqu√≠</a>

            <!-- Tema 3 -->
            <center>
                <h1>Tema 3</h1>
            </center>
            <center>
                <h2>Variables Aleatorias. </h2>
            </center>

            <img
                src="https://stats.libretexts.org/@api/deki/files/16945/clipboard_e25dd712df7f29256eedc5b306b1d828d.png" />
                
            <ul>
                <li>
                    <h4>3.1 Variables aleatorias discretas:</h4>
                    <a href="videos/t3discretas.mp4">Video</a>
                    <ul>
                        <li><b>3.1.1 Distribuci√≥n de probabilidad en forma general:</b>
                            <p>La distribuci√≥n de probabilidad de una variable aleatoria discreta asigna una
                                probabilidad a cada valor posible de la variable. La suma de todas las probabilidades
                                debe ser igual a 1.</p>
                        </li>
                        <li><b>3.1.2 Valor esperado:</b>
                            <p>El valor esperado (o esperanza matem√°tica) de una variable aleatoria discreta es la suma
                                de todos los valores posibles de la variable, cada uno multiplicado por su probabilidad
                                correspondiente. Se calcula como \(E(X) = \sum_{i} x_i P(x_i)\).</p>
                        </li>
                        <li><b>3.1.3 Varianza, desviaci√≥n est√°ndar:</b>
                            <p>La varianza mide la dispersi√≥n de una variable aleatoria respecto a su valor esperado. Se
                                calcula como \(Var(X) = \sum_{i} (x_i - E(X))^2 P(x_i)\). La desviaci√≥n est√°ndar es la
                                ra√≠z cuadrada de la varianza.</p>
                        </li>
                        <li><b>3.1.4 Funci√≥n acumulada:</b>
                            <p>La funci√≥n de distribuci√≥n acumulada (FDA) de una variable aleatoria discreta es una
                                funci√≥n que, para cualquier valor x, da la probabilidad de que la variable aleatoria sea
                                menor o igual a x. Se define como \(F(x) = P(X \leq x)\).</p>
                        </li>
                    </ul>
                </li>
                <li>
                    <h4>3.2 Variables aleatorias continuas:</h4>
                    <a href="videos/t3aleatorias.mp4">Video</a>
                    <ul>
                        <li><b>3.2.1 Distribuci√≥n de probabilidad en forma general:</b>
                            <p>La distribuci√≥n de probabilidad de una variable aleatoria continua se describe mediante
                                una funci√≥n de densidad de probabilidad (FDP). La probabilidad de que la variable
                                aleatoria tome un valor dentro de un intervalo se obtiene integrando la FDP sobre ese
                                intervalo.</p>
                        </li>
                        <li><b>3.2.2 Valor esperado:</b>
                            <p>El valor esperado de una variable aleatoria continua se calcula como la integral del
                                producto del valor de la variable y su funci√≥n de densidad de probabilidad, es decir,
                                \(E(X) = \int_{-\infty}^{\infty} x f(x) \, dx\).</p>
                        </li>
                        <li><b>3.2.3 Varianza, desviaci√≥n est√°ndar:</b>
                            <p>La varianza de una variable aleatoria continua se calcula como la integral del cuadrado
                                de la diferencia entre el valor de la variable y el valor esperado, multiplicada por la
                                funci√≥n de densidad de probabilidad: \(Var(X) = \int_{-\infty}^{\infty} (x - E(X))^2
                                f(x) \, dx\). La desviaci√≥n est√°ndar es la ra√≠z cuadrada de la varianza.</p>
                        </li>
                        <li><b>3.2.4 Funci√≥n acumulada:</b>
                            <p>La funci√≥n de distribuci√≥n acumulada (FDA) de una variable aleatoria continua es la
                                integral de la funci√≥n de densidad de probabilidad desde menos infinito hasta x: \(F(x)
                                = \int_{-\infty}^{x} f(t) \, dt\).</p>
                        </li>
                        <li><b>3.2.5 C√°lculos de probabilidad:</b>
                            <p>Para calcular la probabilidad de que una variable aleatoria continua caiga dentro de un
                                cierto intervalo \([a, b]\), se integra la funci√≥n de densidad de probabilidad sobre ese
                                intervalo: \(P(a \leq X \leq b) = \int_{a}^{b} f(x) \, dx\).</p>
                        </li>
                    </ul>
                </li>
            </ul>

            <!-- Tema 4 -->
            <center>
                <h1>Tema 4</h1>
            </center>
            <center>
                <h2>Distribuciones de Probabilidad</h2>
                <a href="videos/T4.mp4">Video</a>
            </center>

            <img   src="https://educcando.com/wp-content/uploads/2023/01/Distribucion-de-probabilidad-continua-uniforme.jpg" />

            <ul>
                <li>
                    <h4>4.1 Funci√≥n de probabilidad:</h4>
                    <p>Una funci√≥n de probabilidad describe la probabilidad de que una variable aleatoria tome un valor espec√≠fico. Para variables discretas, se usa la funci√≥n de probabilidad de masa, mientras que para variables continuas, se utiliza la funci√≥n de densidad de probabilidad. Estas funciones son esenciales para definir completamente la distribuci√≥n de una variable aleatoria y permiten calcular probabilidades y momentos como la media y la varianza.</p>
                </li>
                <li>
                    <h4>4.2 Distribuci√≥n binomial:</h4>
                    <p>La distribuci√≥n binomial modela el n√∫mero de √©xitos en una secuencia de n ensayos independientes, cada uno con una probabilidad de √©xito p. Es √∫til en situaciones donde hay un n√∫mero fijo de ensayos y dos posibles resultados (√©xito o fracaso) en cada ensayo. La funci√≥n de probabilidad es \(P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}\), donde \(\binom{n}{k}\) es el coeficiente binomial. La media y la varianza de la distribuci√≥n binomial son \(E(X) = np\) y \(Var(X) = np(1-p)\), respectivamente.</p>
                    <ul>
                        <li><strong>Funci√≥n de probabilidad:</strong> \(P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}\)</li>
                        <li><strong>Media:</strong> \(E(X) = np\)</li>
                        <li><strong>Varianza:</strong> \(Var(X) = np(1-p)\)</li>
                        <li><strong>¬øCu√°ndo usar?</strong> Cuando se tienen un n√∫mero fijo de ensayos con dos resultados posibles y se quiere modelar el n√∫mero de √©xitos.</li>
                        <li><strong>Python:</strong> Utilizar la funci√≥n `binom.pmf` de SciPy para calcular probabilidades.</li>
                    </ul>
                </li>
                <li>
                    <h4>4.3 Distribuci√≥n hipergeom√©trica:</h4>
                    <p>La distribuci√≥n hipergeom√©trica describe la probabilidad de k √©xitos en n extracciones sin reemplazo de una poblaci√≥n de tama√±o N que contiene exactamente K √©xitos. Es √∫til en situaciones donde la muestra se toma sin reemplazo, lo que significa que cada elemento seleccionado afecta la probabilidad de selecci√≥n de los siguientes. La funci√≥n de probabilidad es \(P(X = k) = \frac{\binom{K}{k} \binom{N-K}{n-k}}{\binom{N}{n}}\). La media y la varianza de la distribuci√≥n hipergeom√©trica son \(E(X) = n\frac{K}{N}\) y \(Var(X) = n\frac{K}{N}\frac{N-K}{N}\frac{N-n}{N-1}\), respectivamente.</p>
                    <ul>
                        <li><strong>Funci√≥n de probabilidad:</strong> \(P(X = k) = \frac{\binom{K}{k} \binom{N-K}{n-k}}{\binom{N}{n}}\)</li>
                        <li><strong>Media:</strong> \(E(X) = n\frac{K}{N}\)</li>
                        <li><strong>Varianza:</strong> \(Var(X) = n\frac{K}{N}\frac{N-K}{N}\frac{N-n}{N-1}\)</li>
                        <li><strong>¬øCu√°ndo usar?</strong> Cuando se realizan extracciones sin reemplazo de una poblaci√≥n finita.</li>
                        <li><strong>Python:</strong> Utilizar la funci√≥n `hypergeom.pmf` de SciPy para calcular probabilidades.</li>
                    </ul>
                </li>
                <li>
                    <h4>4.4 Distribuci√≥n de Poisson:</h4>
                    <p>La distribuci√≥n de Poisson modela el n√∫mero de eventos que ocurren en un intervalo de tiempo fijo o en una regi√≥n espacial fija, dada una tasa promedio de ocurrencia Œª. Es √∫til para modelar eventos raros en grandes poblaciones o intervalos de tiempo. La funci√≥n de probabilidad es \(P(X = k) = \frac{e^{-\lambda} \lambda^k}{k!}\). La media y la varianza de la distribuci√≥n de Poisson son ambas iguales a Œª. Esta distribuci√≥n se usa com√∫nmente en an√°lisis de conteos, como el n√∫mero de llamadas a un centro de atenci√≥n al cliente en una hora.</p>
                    <ul>
                        <li><strong>Funci√≥n de probabilidad:</strong> \(P(X = k) = \frac{e^{-\lambda} \lambda^k}{k!}\)</li>
                        <li><strong>Media:</strong> \(E(X) = \lambda\)</li>
                        <li><strong>Varianza:</strong> \(Var(X) = \lambda\)</li>
                        <li><strong>¬øCu√°ndo usar?</strong> Para modelar la ocurrencia de eventos raros en un intervalo de tiempo o espacio.</li>
                        <li><strong>Python:</strong> Utilizar la funci√≥n `poisson.pmf` de SciPy para calcular probabilidades.</li>
                    </ul>
                </li>
                <li>
                    <h4>4.5 Distribuci√≥n normal:</h4>
                    <p>La distribuci√≥n normal es una distribuci√≥n continua que se caracteriza por su media Œº y desviaci√≥n est√°ndar œÉ. Su funci√≥n de densidad de probabilidad es \(f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}\). La distribuci√≥n normal es sim√©trica alrededor de su media, y sus propiedades hacen que sea extremadamente √∫til en estad√≠stica, especialmente debido al teorema central del l√≠mite, que establece que la suma de un gran n√∫mero de variables aleatorias independientes y identicamente distribuidas tiende a una distribuci√≥n normal, independientemente de la distribuci√≥n original de las variables.</p>
                    <ul>
                        <li><strong>Funci√≥n de probabilidad:</strong> \(f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}\)</li>
                        <li><strong>Media:</strong> \(E(X) = \mu\)</li>
                        <li><strong>Varianza:</strong> \(Var(X) = \sigma^2\)</li>
                        <li><strong>¬øCu√°ndo usar?</strong> Cuando se asume que los datos siguen una distribuci√≥n sim√©trica y el Teorema Central del L√≠mite se puede aplicar.</li>
                        <li><strong>Python:</strong> Utilizar la funci√≥n `norm.pdf` de SciPy para calcular la densidad de probabilidad.</li>
                    </ul>
                </li>
                <li>
                    <h4>4.6 Distribuci√≥n T de Student:</h4>
                    <p>La distribuci√≥n T de Student se utiliza para estimar la media de una poblaci√≥n normalmente distribuida cuando el tama√±o de la muestra es peque√±o y la desviaci√≥n est√°ndar de la poblaci√≥n es desconocida. La distribuci√≥n T tiene colas m√°s largas que la distribuci√≥n normal, lo que refleja una mayor incertidumbre en las estimaciones.</p>
                    <ul>
                        <li><strong>Funci√≥n de probabilidad:</strong> Depende de los grados de libertad y se usa la funci√≥n T de Student.</li>
                        <li><strong>Media:</strong> 0 (para la distribuci√≥n est√°ndar T de Student)</li>
                        <li><strong>Varianza:</strong> \(\frac{\nu}{\nu - 2}\) para \(\nu > 2\)</li>
                        <li><strong>¬øCu√°ndo usar?</strong> Cuando se estima la media de una poblaci√≥n normalmente distribuida con un tama√±o de muestra peque√±o.</li>
                        <li><strong>Python:</strong> Utilizar la funci√≥n `t.pdf` de SciPy para calcular la densidad de probabilidad.</li>
                    </ul>
                </li>
                <li>
                    <h4>4.7 Distribuci√≥n Chi cuadrada:</h4>
                    <p>La distribuci√≥n Chi cuadrada es una distribuci√≥n continua que surge con frecuencia en pruebas de hip√≥tesis y an√°lisis de varianza. Se utiliza para evaluar la varianza en una poblaci√≥n normalmente distribuida y en la prueba de independencia en tablas de contingencia. La distribuci√≥n Chi cuadrada se caracteriza por un par√°metro de grados de libertad. Su funci√≥n de densidad de probabilidad es \(f(x) = \frac{1}{2^{k/2} \Gamma(k/2)} x^{(k/2)-1} e^{-x

                        <center>
                            <h1>Tema 5</h1>
                        </center>
                        <center>
                            <h2>Regresi√≥n Lineal</h2>
                        </center>
                        <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/1920px-Linear_regression.svg.png" />
                        <ul>
                            <li>
                                <h4>5.1 Regresi√≥n y correlaci√≥n:</h4>
                                <ul>
                                    <li><b>5.1.1 Diagrama de dispersi√≥n:</b>
                                        <p>El diagrama de dispersi√≥n es una representaci√≥n gr√°fica de dos variables cuantitativas que muestra la relaci√≥n entre ellas. Cada punto en el gr√°fico representa un par de valores de las dos variables.</p>
                                    </li>
                                    <li><b>5.1.2 Regresi√≥n lineal simple:</b>
                                        <p>La regresi√≥n lineal simple es un m√©todo para modelar la relaci√≥n entre una variable dependiente y una variable independiente mediante una l√≠nea recta. La ecuaci√≥n de la l√≠nea de regresi√≥n es \(y = mx + b\), donde \(m\) es la pendiente y \(b\) es la intersecci√≥n.</p>
                                    </li>
                                    <li><b>5.1.3 Correlaci√≥n:</b>
                                        <p>La correlaci√≥n mide la fuerza y la direcci√≥n de la relaci√≥n lineal entre dos variables. Se calcula mediante el coeficiente de correlaci√≥n de Pearson, que var√≠a entre -1 y 1.</p>
                                    </li>
                                    <li><b>5.1.4 Determinaci√≥n y an√°lisis de los coeficientes de correlaci√≥n y de determinaci√≥n:</b>
                                        <p>El coeficiente de correlaci√≥n \(r\) indica la fuerza y la direcci√≥n de la relaci√≥n lineal entre dos variables. El coeficiente de determinaci√≥n \(r^2\) indica la proporci√≥n de la variabilidad en la variable dependiente que es explicada por la variable independiente.</p>
                                    </li>
                                    <li><b>5.1.5 Distribuci√≥n normal bidimensional:</b>
                                        <p>La distribuci√≥n normal bidimensional es una extensi√≥n de la distribuci√≥n normal para dos variables. Se caracteriza por dos medias, dos varianzas y una covarianza que describe la relaci√≥n entre las dos variables.</p>
                                    </li>
                                    <li><b>5.1.6 Intervalos de confianza y pruebas para el coeficiente de correlaci√≥n:</b>
                                        <p>Los intervalos de confianza para el coeficiente de correlaci√≥n proporcionan un rango de valores plausibles para el coeficiente de correlaci√≥n en la poblaci√≥n. Las pruebas de hip√≥tesis se utilizan para evaluar si el coeficiente de correlaci√≥n es significativamente diferente de cero.</p>
                                    </li>
                                    <li><b>5.1.7 Errores de medici√≥n:</b>
                                        <p>Los errores de medici√≥n se refieren a las diferencias entre los valores observados y los valores verdaderos de una variable. Pueden afectar la precisi√≥n y la validez de los resultados de la regresi√≥n y la correlaci√≥n.</p>
                                    </li>
                                </ul>
                            </li>
                        </ul>


                        
</body>

</html>