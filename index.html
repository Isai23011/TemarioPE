<!DOCTYPE html>
<html>

<head>
    <link rel="stylesheet" href="style.css">
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
    <title>Temario</title>
</head>

<body>
    <center>
        <h1>Tema 1</h1>
    </center>
    <center>
        <h2>Estadistica descriptiva</h2>
    </center>
    <img src="https://www.questionpro.com/blog/wp-content/uploads/2021/05/1711-Portada-estadistica-descriptiva.jpg" />

    <!-- Tema 1 -->
    <ul>
        <li>
            <h4>1.1 Conceptos básicos de estadística.</h4>
            <ul>
                <li><b>Definición de Estadística:</b>
                    La estadística es la ciencia que estudia cómo recopilar, organizar, analizar e interpretar datos
                    para tomar decisiones informadas. Se divide en dos ramas principales:
                    <ul>
                        <li><b>Estadística descriptiva:</b> Se encarga de resumir y describir las características de un
                            conjunto de datos.</li>
                        <li><b>Estadística inferencial:</b> Utiliza una muestra de datos para hacer inferencias o
                            generalizaciones sobre una población más grande.</li>
                    </ul>
                </li>

                <br>

                <li><b>Teoría de Decisión:</b>
                    La teoría de decisión se enfoca en la toma de decisiones óptimas bajo condiciones de incertidumbre.
                    Involucra la identificación de diferentes alternativas, la evaluación de sus posibles resultados y
                    la selección de la opción que maximiza los beneficios o minimiza los costos.
                    <ul>
                        <li><b>Decisor:</b> Persona o entidad que toma la decisión.</li>
                        <li><b>Alternativas:</b> Opciones disponibles entre las cuales se puede elegir.</li>
                        <li><b>Estados de la naturaleza:</b> Condiciones o eventos que pueden ocurrir y que afectan el
                            resultado de la decisión.</li>
                        <li><b>Pagos o recompensas:</b> Consecuencias asociadas a cada combinación de alternativa y
                            estado de la naturaleza.</li>
                        <li><b>Criterio de decisión:</b> Regla o principio usado para seleccionar la mejor alternativa
                            (por ejemplo, maximización de la utilidad esperada).</li>
                    </ul>
                </li>

                <br>

                <li><b>Población:</b>
                    En estadística, la población se refiere al conjunto completo de individuos, elementos, o eventos que
                    poseen alguna característica común y sobre la cual se desea realizar inferencias. Puede ser finita
                    (por ejemplo, todos los estudiantes de una escuela) o infinita (por ejemplo, todos los posibles
                    resultados de lanzar un dado).
                </li>

                <br>

                <li><b>Muestra Aleatoria:</b>
                    Una muestra aleatoria es un subconjunto de la población seleccionado de tal manera que cada
                    individuo tiene una probabilidad conocida y no nula de ser incluido. Las muestras aleatorias son
                    fundamentales en estadística porque permiten hacer inferencias sobre la población con un cierto
                    nivel de confianza.
                    <ul>
                        <li><b>Muestreo aleatorio simple:</b> Cada miembro de la población tiene la misma probabilidad
                            de ser seleccionado.</li>
                        <li><b>Muestreo sistemático:</b> Se selecciona cada ésimo individuo de una lista ordenada de la
                            población.</li>
                        <li><b>Muestreo estratificado:</b> La población se divide en subgrupos homogéneos (estratos) y
                            se selecciona una muestra aleatoria de cada estrato.</li>
                        <li><b>Muestreo por conglomerados:</b> La población se divide en grupos heterogéneos
                            (conglomerados) y se selecciona una muestra aleatoria de estos conglomerados.</li>
                    </ul>
                </li>
                <br>

                <li><b>Parámetros Aleatorios:</b>
                    Los parámetros aleatorios son características numéricas de una población que se desconocen y que se
                    estiman a partir de muestras. Ejemplos de parámetros incluyen:
                    <ul>
                        <li><b>Media (μ):</b> Valor promedio de la población.</li>
                        <li><b>Varianza (σ²):</b> Medida de la dispersión de los valores de la población respecto a la
                            media.</li>
                        <li><b>Proporción (p):</b> Fracción de la población que posee una determinada característica.
                        </li>
                    </ul>
                    Estos parámetros se contrastan con las <b>estadísticas muestrales</b>, que son valores calculados a
                    partir de una muestra y utilizados para estimar los parámetros poblacionales. Por ejemplo, la media
                    muestral se usa para estimar la media poblacional (μ).
                </li>
            </ul>
        </li>

        <li>
            <h4>1.2 Descripción de datos.</h4>
            <ul>
                <li><b>Datos agrupados y no agrupados:</b>
                    <ul>
                        <li><b>Datos no agrupados:</b> Son datos que se presentan en su forma original sin ninguna
                            organización. Por ejemplo, las alturas individuales de un grupo de estudiantes.</li>
                        <li><b>Datos agrupados:</b> Son datos organizados en tablas de frecuencias. Por ejemplo, las
                            alturas de un grupo de estudiantes organizadas en intervalos de altura.</li>
                    </ul>
                </li>

                <br>

                <li><b>Frecuencia de clase:</b>
                    Es el número de observaciones que caen dentro de un intervalo de clase específico en una
                    distribución de frecuencias.
                </li>

                <br>

                <li><b>Frecuencia relativa:</b>
                    Es la proporción o fracción de observaciones que pertenecen a una clase en particular. Se calcula
                    dividiendo la frecuencia de clase por el número total de observaciones.
                </li>

                <br>

                <li><b>Punto medio:</b>
                    Es el valor central de un intervalo de clase. Se calcula sumando los límites inferior y superior del
                    intervalo y dividiendo por dos.
                </li>

                <br>

                <li><b>Límites:</b>
                    Los límites de clase son los valores que marcan el inicio y el final de un intervalo de clase.
                    Existen dos tipos:
                    <ul>
                        <li><b>Límites reales:</b> Incluyen todos los valores posibles dentro del intervalo,
                            considerando cualquier posible valor decimal o fraccionario.</li>
                        <li><b>Límites aparentes:</b> Son los valores que se presentan como los bordes del intervalo y
                            no consideran los decimales o fraccionarios.</li>
                    </ul>
                </li>
            </ul>
        </li>


        <li>
            <h4>1.3 Medidas de tendencia central y de dispersión.</h4>
            <ul>
                <li><b>Media aritmética:</b>
                    Es el promedio de un conjunto de datos y se calcula sumando todos los valores y dividiendo por el
                    número total de observaciones.
                </li>

                <br>

                <li><b>Media geométrica:</b>
                    Es la raíz enésima del producto de n valores, útil especialmente para datos que representan tasas de
                    crecimiento.
                </li>

                <br>

                <li><b>Media ponderada:</b>
                    Es similar a la media aritmética pero asignando diferentes pesos a diferentes valores. Se calcula
                    multiplicando cada valor por su peso, sumando estos productos y dividiendo por la suma de los pesos.
                </li>

                <br>

                <li><b>Mediana:</b>
                    Es el valor que divide un conjunto de datos ordenados en dos partes iguales. Si el número de
                    observaciones es impar, la mediana es el valor central; si es par, es el promedio de los dos valores
                    centrales.
                </li>

                <br>

                <li><b>Moda:</b>
                    Es el valor o valores que aparecen con mayor frecuencia en un conjunto de datos. Un conjunto de
                    datos puede tener una moda (unimodal), dos modas (bimodal) o más (multimodal).
                </li>

                <br>

                <li><b>Medidas de dispersión:</b>
                    Las medidas de dispersión describen la variabilidad o dispersión de los datos respecto a la
                    tendencia central.
                    <ul>
                        <li><b>Varianza (σ²):</b>
                            Es la media de los cuadrados de las desviaciones de los valores respecto a la media. Indica
                            cuánto varían los datos respecto a la media.
                        </li>
                        <li><b>Desviación estándar (σ):</b>
                            Es la raíz cuadrada de la varianza y proporciona una medida de dispersión en las mismas
                            unidades que los datos originales.
                        </li>
                        <li><b>Desviación media:</b>
                            Es la media de las desviaciones absolutas respecto a la media.
                        </li>
                        <li><b>Desviación mediana:</b>
                            Es la mediana de las desviaciones absolutas respecto a la mediana del conjunto de datos.
                        </li>
                        <li><b>Rango:</b>
                            Es la diferencia entre el valor máximo y el valor mínimo de un conjunto de datos.
                            Proporciona una medida sencilla de la dispersión.
                        </li>
                    </ul>
                </li>
            </ul>
        </li>

        <li>
            <h4>1.4 Parámetros para datos agrupados.</h4>
            <ul>
                <li>Estos parámetros permiten resumir y caracterizar adecuadamente
                    un conjunto de datos cuando estos se presentan de manera agrupada.</li>
            </ul>
        </li>

        <li>
            <h4>1.5 Distribución de frecuencias.</h4>
            <ul>
                <li>La distribución de frecuencias permite analizar la forma,
                    dispersión y tendencia central de un conjunto de datos,
                    facilitando su interpretación y comprensión.</li>
            </ul>
        </li>

        <li>
            <h4>1.6 Técnicas de agrupación de datos.</h4>
            <ul>
                <li>Estas técnicas permiten estructurar adecuadamente
                    los datos, facilitando su análisis, visualización e
                    interpretación estadística.</li>
            </ul>
        </li>

        <li>
            <h4>1.7 Técnicas de muestreo.</h4>
            <ul>
                <li>Estas técnicas permiten obtener muestras representativas de la
                    población, de acuerdo a los objetivos y características del estudio.
                </li>
            </ul>
        </li>
    </ul>
    <b>Ejemplos en el siguiente link:</b>

    <a href="https://nbviewer.org/github/imac22/Frecuencias/blob/685d5fdfe6a3038fe4dfe63c0c09bedb8ac41843/numeros.ipynb">Aquí</a>

    <!-- Tema 2 -->
    <center>
        <h1>Tema 2</h1>
    </center>
    <center>
        <h2>Fundamentos de la Teoría de Probabilidad.</h2>
    </center>
    <img src="https://www.esan.edu.pe/images/blog/2016/10/10/probabilidades-principal.jpg" />

    <ul>
        <li>
            <h4>2.1 Conceptos básicos de estadística.</h4>
            <ul>
                <li>Las técnicas de conteo son métodos utilizados en combinatoria y probabilidad para contar el número
                    de formas en que se pueden realizar ciertas acciones o formar conjuntos. A continuación, se
                    describen algunas técnicas de conteo fundamentales:</li>

                <br>

                <li><b>2.1.1 Principio aditivo.</b>
                    El principio aditivo se utiliza cuando se cuenta el número total de elementos en una unión de
                    conjuntos disjuntos. Si tenemos varios conjuntos que no tienen elementos en común, el número total
                    de elementos es la suma de los elementos de cada conjunto.
                </li>

                <br>

                <b>Ejemplo</b>
                Si hay 3 maneras de elegir un objeto del conjunto A y 4 maneras de elegir un objeto del conjunto B, y A
                y B son disjuntos, entonces hay 3 + 4 = 7 maneras de elegir un objeto de A o B.

                <br>
                <br>

                <li><b> 2.1.2 Principio multiplicativo:</b>
                    El principio multiplicativo se utiliza cuando se cuenta el número total de formas en que se pueden
                    realizar varias acciones secuenciales. Si una acción se puede realizar de 𝑛 maneras y una segunda
                    acción se puede realizar de 𝑚 maneras, entonces hay 𝑛 × 𝑚 maneras de realizar ambas acciones.
                </li>

                <br>

                <b>Ejemplo</b>
                Si hay 3 maneras de elegir un primer objeto y 4 maneras de elegir un segundo objeto, entonces hay 3 × 4
                = 12 maneras de elegir ambos objetos.

                <br>
                <br>

                <li><b>2.1.3 Notación Factorial:</b>
                    La notación factorial (denotada como 𝑛!) se utiliza para contar el número de maneras en que se
                    pueden ordenar 𝑛 elementos distintos.
                </li>

                <br>

                <b>Formula</b>
                <p>\[n! = n × (n − 1) × (n − 2) × ⋯ × 1\]</p>

                <b>Ejemplo</b>
                <p>\[5! = 5 × 4 × 3 × 2 × 1 = 120\]</p>

                <br>
                <br>

                <li><b> 2.1.4 Permutaciones:</b>
                    Las permutaciones son arreglos ordenados de un conjunto de elementos. El número de permutaciones de
                    𝑛 elementos es 𝑛!. Si se seleccionan 𝑟 elementos de un conjunto de 𝑛 elementos para formar
                    permutaciones, se utiliza la notación 𝑃(𝑛,𝑟).
                </li>

                <br>

                <b>Formula</b>
                <p>\[ P(n, r) = \frac{n!}{(n-r)!} \]</p>

                <b>Ejemplo</b>
                El número de maneras de ordenar 3 elementos de un conjunto de 5 elementos es: \[𝑃(5,3) = \frac{5!}{(5 −
                3)!} = \frac{5 × 4 × 3 × 2 × 1} {2 × 1} = 60\]

                <br>
                <br>

                <li><b> 2.1.5 Combinaciones:</b>
                    Las combinaciones son selecciones no ordenadas de elementos de un conjunto. El número de
                    combinaciones de 𝑛 elementos tomados 𝑟 a la vez se denota como 𝐶(𝑛,𝑟) o (𝑛 / 𝑟).
                </li>

                <br>

                <b>Formula</b>
                <p>\[C(n,r) = \frac{n}{r} = \frac{n!}{r!(n−r)!}\]</p>

                <b>Ejemplo</b>
                El número de maneras de elegir 3 elementos de un conjunto de 5 elementos es:\[C(5,3) =
                \frac{5!}{3!(5-3)!} = \frac{5 \times 4 \times 3 \times 2 \times 1}{3 \times 2 \times 1 \times 2 \times
                1} = 10\]

                <br>
                <br>

                <li><b> 2.1.6 Diagrama de Árbol:</b>
                    Un diagrama de árbol es una representación gráfica que se utiliza para visualizar y contar el número
                    de resultados posibles de un evento o serie de eventos.
                </li>

                <br>

                <b>Ejemplo</b>
                Si se lanza una moneda y luego se lanza un dado, un diagrama de árbol puede mostrar todas las
                combinaciones posibles de resultados (cara/cruz seguido de 1, 2, 3, 4, 5, 6).

                <br>

                <br>

                <li><b> 2.1.7 Teorema del Binomio:</b>
                    El teorema del binomio proporciona una fórmula para expandir una potencia de un binomio. Se utiliza
                    en combinatoria para contar combinaciones de elementos con repetición.
                </li>

                <br>

                <li>
                    <h4>2.1 Conceptos básicos de estadística.</h4>
                    <ul>
                        <li>Las técnicas de conteo son métodos utilizados en combinatoria y probabilidad para contar el
                            número de formas en que se pueden realizar ciertas acciones o formar conjuntos. A
                            continuación, se describen algunas técnicas de conteo fundamentales:</li>
                        <ul>
                            <li><strong>Permutaciones</strong>: La cantidad de maneras en que se pueden ordenar un
                                conjunto de objetos.</li>
                            <li><strong>Combinaciones</strong>: La cantidad de maneras en que se pueden seleccionar
                                objetos de un conjunto, sin importar el orden.</li>
                            <li><strong>Principio de la multiplicación</strong>: Si una tarea puede realizarse de \( n
                                \) maneras y otra tarea puede realizarse de \( m \) maneras, entonces ambas tareas
                                pueden realizarse de \( n \times m \) maneras.</li>
                            <li><strong>Principio de la adición</strong>: Si un evento puede ocurrir de \( n \) maneras
                                y otro evento puede ocurrir de \( m \) maneras, y estos eventos no pueden ocurrir
                                simultáneamente, entonces el número total de maneras en que uno de los eventos puede
                                ocurrir es \( n + m \).</li>
                        </ul>
                    </ul>
                </li>
                <li>
                    <h4>2.2 Teoría elemental de probabilidad.</h4>
                    <ul>
                        <li>La teoría elemental de probabilidad es una rama de las matemáticas que estudia los fenómenos
                            aleatorios y los eventos inciertos. Sus conceptos básicos incluyen:</li>
                        <ul>
                            <li><strong>Experimento aleatorio</strong>: Un proceso que produce un resultado incierto.
                            </li>
                            <li><strong>Evento</strong>: Un subconjunto de posibles resultados de un experimento
                                aleatorio.</li>
                            <li><strong>Probabilidad</strong>: Una medida cuantitativa de la incertidumbre asociada con
                                un evento.</li>
                        </ul>
                    </ul>
                </li>
                <li>
                    <h4>2.3 Probabilidad de Eventos.</h4>
                    <ul>
                        <li><strong>Definición de espacio muestral</strong>: El conjunto de todos los posibles
                            resultados de un experimento aleatorio. Por ejemplo, al lanzar un dado, el espacio muestral
                            es {1, 2, 3, 4, 5, 6}.</li>
                        <li><strong>Definición de evento</strong>: Cualquier subconjunto del espacio muestral. Por
                            ejemplo, obtener un número par al lanzar un dado puede ser el evento {2, 4, 6}.</li>
                        <li><strong>Simbología</strong>:</li>
                        <ul>
                            <li><strong>P(E)</strong>: La probabilidad de que ocurra el evento E.</li>
                            <li><strong>E'</strong>: El complemento de E, que representa todos los resultados en el
                                espacio muestral que no están en E.</li>
                        </ul>
                        <li><strong>Unión e intersección</strong>:</li>
                        <ul>
                            <li><strong>Unión (E ∪ F)</strong>: Un evento que ocurre si ocurre E, F, o ambos.</li>
                            <li><strong>Intersección (E ∩ F)</strong>: Un evento que ocurre si ocurren tanto E como F.
                            </li>
                        </ul>
                        <li><strong>Diagramas de Venn</strong>: Los diagramas de Venn son una herramienta gráfica para
                            representar visualmente la relación entre diferentes eventos en un espacio muestral.</li>
                    </ul>
                </li>
                <li>
                    <h4>2.4 Probabilidad con Técnicas de Conteo.</h4>
                    <ul>
                        <li><strong>Axiomas de probabilidad</strong>:</li>
                        <ul>
                            <li>La probabilidad de un evento es un número no negativo: \( P(E) \geq 0 \).</li>
                            <li>La probabilidad del espacio muestral completo es 1: \( P(S) = 1 \).</li>
                            <li>Si dos eventos E y F son mutuamente excluyentes (es decir, \( E \cap F = \emptyset \)),
                                entonces \( P(E \cup F) = P(E) + P(F) \).</li>
                        </ul>
                        <li><strong>Teoremas de probabilidad</strong>:</li>
                        <ul>
                            <li>Teorema de la probabilidad total: Si \( \{A_1, A_2, ..., A_n\} \) es una partición del
                                espacio muestral S, entonces \( P(B) = \sum_{i=1}^n P(B \cap A_i) \).</li>
                        </ul>
                    </ul>
                </li>
                <li>
                    <h4>2.5 Probabilidad condicional.</h4>
                    <ul>
                        <li><strong>Dependiente e Independiente</strong>:</li>
                        <ul>
                            <li>Probabilidad condicional: La probabilidad de un evento A dado que otro evento B ha
                                ocurrido, denotada como \( P(A|B) \).</li>
                            <li>Eventos dependientes: Dos eventos A y B son dependientes si la ocurrencia de uno afecta
                                la probabilidad del otro.</li>
                            <li>Eventos independientes: Dos eventos A y B son independientes si \( P(A \cap B) =
                                P(A)P(B) \).</li>
                        </ul>
                    </ul>
                </li>
                <li>
                    <h4>2.6 Ley multiplicativa.</h4>
                    <ul>
                        <li>La ley multiplicativa para eventos independientes establece que \( P(A \cap B) = P(A)P(B)
                            \).</li>
                    </ul>
                </li>
                <li>
                    <h4>2.7 Eventos independientes: Regla de Bayes.</h4>
                    <ul>
                        <li>Regla de Bayes: Una fórmula que describe la probabilidad de un evento, basada en el
                            conocimiento previo de condiciones que podrían estar relacionadas con el evento. Se expresa
                            como:</li>
                        <li>\[ P(A|B) = \frac{P(B|A)P(A)}{P(B)} \]</li>
                        <li>Esta regla es fundamental en la estadística y en muchas aplicaciones de la teoría de
                            probabilidad.</li>
                    </ul>
                </li>
            </ul>
            <b>Ejemplos en el siguiente link:</b>

            <a href="https://nbviewer.org/github/EduardoGomezTics/Problemas_Equipo/blob/045688584291a323a6292a43198e4dd624f7ca24/Main.ipynb">Aquí</a>

            <!-- Tema 3 -->
            <center>
                <h1>Tema 3</h1>
            </center>
            <center>
                <h2>Variables Aleatorias. </h2>
            </center>

            <img
                src="https://stats.libretexts.org/@api/deki/files/16945/clipboard_e25dd712df7f29256eedc5b306b1d828d.png" />
                
            <ul>
                <li>
                    <h4>3.1 Variables aleatorias discretas:</h4>
                    <a href="videos/t3discretas.mp4">Video</a>
                    <ul>
                        <li><b>3.1.1 Distribución de probabilidad en forma general:</b>
                            <p>La distribución de probabilidad de una variable aleatoria discreta asigna una
                                probabilidad a cada valor posible de la variable. La suma de todas las probabilidades
                                debe ser igual a 1.</p>
                        </li>
                        <li><b>3.1.2 Valor esperado:</b>
                            <p>El valor esperado (o esperanza matemática) de una variable aleatoria discreta es la suma
                                de todos los valores posibles de la variable, cada uno multiplicado por su probabilidad
                                correspondiente. Se calcula como \(E(X) = \sum_{i} x_i P(x_i)\).</p>
                        </li>
                        <li><b>3.1.3 Varianza, desviación estándar:</b>
                            <p>La varianza mide la dispersión de una variable aleatoria respecto a su valor esperado. Se
                                calcula como \(Var(X) = \sum_{i} (x_i - E(X))^2 P(x_i)\). La desviación estándar es la
                                raíz cuadrada de la varianza.</p>
                        </li>
                        <li><b>3.1.4 Función acumulada:</b>
                            <p>La función de distribución acumulada (FDA) de una variable aleatoria discreta es una
                                función que, para cualquier valor x, da la probabilidad de que la variable aleatoria sea
                                menor o igual a x. Se define como \(F(x) = P(X \leq x)\).</p>
                        </li>
                    </ul>
                </li>
                <li>
                    <h4>3.2 Variables aleatorias continuas:</h4>
                    <a href="videos/t3aleatorias.mp4">Video</a>
                    <ul>
                        <li><b>3.2.1 Distribución de probabilidad en forma general:</b>
                            <p>La distribución de probabilidad de una variable aleatoria continua se describe mediante
                                una función de densidad de probabilidad (FDP). La probabilidad de que la variable
                                aleatoria tome un valor dentro de un intervalo se obtiene integrando la FDP sobre ese
                                intervalo.</p>
                        </li>
                        <li><b>3.2.2 Valor esperado:</b>
                            <p>El valor esperado de una variable aleatoria continua se calcula como la integral del
                                producto del valor de la variable y su función de densidad de probabilidad, es decir,
                                \(E(X) = \int_{-\infty}^{\infty} x f(x) \, dx\).</p>
                        </li>
                        <li><b>3.2.3 Varianza, desviación estándar:</b>
                            <p>La varianza de una variable aleatoria continua se calcula como la integral del cuadrado
                                de la diferencia entre el valor de la variable y el valor esperado, multiplicada por la
                                función de densidad de probabilidad: \(Var(X) = \int_{-\infty}^{\infty} (x - E(X))^2
                                f(x) \, dx\). La desviación estándar es la raíz cuadrada de la varianza.</p>
                        </li>
                        <li><b>3.2.4 Función acumulada:</b>
                            <p>La función de distribución acumulada (FDA) de una variable aleatoria continua es la
                                integral de la función de densidad de probabilidad desde menos infinito hasta x: \(F(x)
                                = \int_{-\infty}^{x} f(t) \, dt\).</p>
                        </li>
                        <li><b>3.2.5 Cálculos de probabilidad:</b>
                            <p>Para calcular la probabilidad de que una variable aleatoria continua caiga dentro de un
                                cierto intervalo \([a, b]\), se integra la función de densidad de probabilidad sobre ese
                                intervalo: \(P(a \leq X \leq b) = \int_{a}^{b} f(x) \, dx\).</p>
                        </li>
                    </ul>
                </li>
            </ul>

            <!-- Tema 4 -->
            <center>
                <h1>Tema 4</h1>
            </center>
            <center>
                <h2>Distribuciones de Probabilidad</h2>
                <a href="videos/T4.mp4">Video</a>
            </center>

            <img   src="https://educcando.com/wp-content/uploads/2023/01/Distribucion-de-probabilidad-continua-uniforme.jpg" />

            <ul>
                <li>
                    <h4>4.1 Función de probabilidad:</h4>
                    <p>Una función de probabilidad describe la probabilidad de que una variable aleatoria tome un valor específico. Para variables discretas, se usa la función de probabilidad de masa, mientras que para variables continuas, se utiliza la función de densidad de probabilidad. Estas funciones son esenciales para definir completamente la distribución de una variable aleatoria y permiten calcular probabilidades y momentos como la media y la varianza.</p>
                </li>
                <li>
                    <h4>4.2 Distribución binomial:</h4>
                    <p>La distribución binomial modela el número de éxitos en una secuencia de n ensayos independientes, cada uno con una probabilidad de éxito p. Es útil en situaciones donde hay un número fijo de ensayos y dos posibles resultados (éxito o fracaso) en cada ensayo. La función de probabilidad es \(P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}\), donde \(\binom{n}{k}\) es el coeficiente binomial. La media y la varianza de la distribución binomial son \(E(X) = np\) y \(Var(X) = np(1-p)\), respectivamente.</p>
                    <ul>
                        <li><strong>Función de probabilidad:</strong> \(P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}\)</li>
                        <li><strong>Media:</strong> \(E(X) = np\)</li>
                        <li><strong>Varianza:</strong> \(Var(X) = np(1-p)\)</li>
                        <li><strong>¿Cuándo usar?</strong> Cuando se tienen un número fijo de ensayos con dos resultados posibles y se quiere modelar el número de éxitos.</li>
                        <li><strong>Python:</strong> Utilizar la función `binom.pmf` de SciPy para calcular probabilidades.</li>
                    </ul>
                </li>
                <li>
                    <h4>4.3 Distribución hipergeométrica:</h4>
                    <p>La distribución hipergeométrica describe la probabilidad de k éxitos en n extracciones sin reemplazo de una población de tamaño N que contiene exactamente K éxitos. Es útil en situaciones donde la muestra se toma sin reemplazo, lo que significa que cada elemento seleccionado afecta la probabilidad de selección de los siguientes. La función de probabilidad es \(P(X = k) = \frac{\binom{K}{k} \binom{N-K}{n-k}}{\binom{N}{n}}\). La media y la varianza de la distribución hipergeométrica son \(E(X) = n\frac{K}{N}\) y \(Var(X) = n\frac{K}{N}\frac{N-K}{N}\frac{N-n}{N-1}\), respectivamente.</p>
                    <ul>
                        <li><strong>Función de probabilidad:</strong> \(P(X = k) = \frac{\binom{K}{k} \binom{N-K}{n-k}}{\binom{N}{n}}\)</li>
                        <li><strong>Media:</strong> \(E(X) = n\frac{K}{N}\)</li>
                        <li><strong>Varianza:</strong> \(Var(X) = n\frac{K}{N}\frac{N-K}{N}\frac{N-n}{N-1}\)</li>
                        <li><strong>¿Cuándo usar?</strong> Cuando se realizan extracciones sin reemplazo de una población finita.</li>
                        <li><strong>Python:</strong> Utilizar la función `hypergeom.pmf` de SciPy para calcular probabilidades.</li>
                    </ul>
                </li>
                <li>
                    <h4>4.4 Distribución de Poisson:</h4>
                    <p>La distribución de Poisson modela el número de eventos que ocurren en un intervalo de tiempo fijo o en una región espacial fija, dada una tasa promedio de ocurrencia λ. Es útil para modelar eventos raros en grandes poblaciones o intervalos de tiempo. La función de probabilidad es \(P(X = k) = \frac{e^{-\lambda} \lambda^k}{k!}\). La media y la varianza de la distribución de Poisson son ambas iguales a λ. Esta distribución se usa comúnmente en análisis de conteos, como el número de llamadas a un centro de atención al cliente en una hora.</p>
                    <ul>
                        <li><strong>Función de probabilidad:</strong> \(P(X = k) = \frac{e^{-\lambda} \lambda^k}{k!}\)</li>
                        <li><strong>Media:</strong> \(E(X) = \lambda\)</li>
                        <li><strong>Varianza:</strong> \(Var(X) = \lambda\)</li>
                        <li><strong>¿Cuándo usar?</strong> Para modelar la ocurrencia de eventos raros en un intervalo de tiempo o espacio.</li>
                        <li><strong>Python:</strong> Utilizar la función `poisson.pmf` de SciPy para calcular probabilidades.</li>
                    </ul>
                </li>
                <li>
                    <h4>4.5 Distribución normal:</h4>
                    <p>La distribución normal es una distribución continua que se caracteriza por su media μ y desviación estándar σ. Su función de densidad de probabilidad es \(f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}\). La distribución normal es simétrica alrededor de su media, y sus propiedades hacen que sea extremadamente útil en estadística, especialmente debido al teorema central del límite, que establece que la suma de un gran número de variables aleatorias independientes y identicamente distribuidas tiende a una distribución normal, independientemente de la distribución original de las variables.</p>
                    <ul>
                        <li><strong>Función de probabilidad:</strong> \(f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}\)</li>
                        <li><strong>Media:</strong> \(E(X) = \mu\)</li>
                        <li><strong>Varianza:</strong> \(Var(X) = \sigma^2\)</li>
                        <li><strong>¿Cuándo usar?</strong> Cuando se asume que los datos siguen una distribución simétrica y el Teorema Central del Límite se puede aplicar.</li>
                        <li><strong>Python:</strong> Utilizar la función `norm.pdf` de SciPy para calcular la densidad de probabilidad.</li>
                    </ul>
                </li>
                <li>
                    <h4>4.6 Distribución T de Student:</h4>
                    <p>La distribución T de Student se utiliza para estimar la media de una población normalmente distribuida cuando el tamaño de la muestra es pequeño y la desviación estándar de la población es desconocida. La distribución T tiene colas más largas que la distribución normal, lo que refleja una mayor incertidumbre en las estimaciones.</p>
                    <ul>
                        <li><strong>Función de probabilidad:</strong> Depende de los grados de libertad y se usa la función T de Student.</li>
                        <li><strong>Media:</strong> 0 (para la distribución estándar T de Student)</li>
                        <li><strong>Varianza:</strong> \(\frac{\nu}{\nu - 2}\) para \(\nu > 2\)</li>
                        <li><strong>¿Cuándo usar?</strong> Cuando se estima la media de una población normalmente distribuida con un tamaño de muestra pequeño.</li>
                        <li><strong>Python:</strong> Utilizar la función `t.pdf` de SciPy para calcular la densidad de probabilidad.</li>
                    </ul>
                </li>
                <li>
                    <h4>4.7 Distribución Chi cuadrada:</h4>
                    <p>La distribución Chi cuadrada es una distribución continua que surge con frecuencia en pruebas de hipótesis y análisis de varianza. Se utiliza para evaluar la varianza en una población normalmente distribuida y en la prueba de independencia en tablas de contingencia. La distribución Chi cuadrada se caracteriza por un parámetro de grados de libertad. Su función de densidad de probabilidad es \(f(x) = \frac{1}{2^{k/2} \Gamma(k/2)} x^{(k/2)-1} e^{-x

                        <center>
                            <h1>Tema 5</h1>
                        </center>
                        <center>
                            <h2>Regresión Lineal</h2>
                        </center>
                        <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/1920px-Linear_regression.svg.png" />
                        <ul>
                            <li>
                                <h4>5.1 Regresión y correlación:</h4>
                                <ul>
                                    <li><b>5.1.1 Diagrama de dispersión:</b>
                                        <p>El diagrama de dispersión es una representación gráfica de dos variables cuantitativas que muestra la relación entre ellas. Cada punto en el gráfico representa un par de valores de las dos variables.</p>
                                    </li>
                                    <li><b>5.1.2 Regresión lineal simple:</b>
                                        <p>La regresión lineal simple es un método para modelar la relación entre una variable dependiente y una variable independiente mediante una línea recta. La ecuación de la línea de regresión es \(y = mx + b\), donde \(m\) es la pendiente y \(b\) es la intersección.</p>
                                    </li>
                                    <li><b>5.1.3 Correlación:</b>
                                        <p>La correlación mide la fuerza y la dirección de la relación lineal entre dos variables. Se calcula mediante el coeficiente de correlación de Pearson, que varía entre -1 y 1.</p>
                                    </li>
                                    <li><b>5.1.4 Determinación y análisis de los coeficientes de correlación y de determinación:</b>
                                        <p>El coeficiente de correlación \(r\) indica la fuerza y la dirección de la relación lineal entre dos variables. El coeficiente de determinación \(r^2\) indica la proporción de la variabilidad en la variable dependiente que es explicada por la variable independiente.</p>
                                    </li>
                                    <li><b>5.1.5 Distribución normal bidimensional:</b>
                                        <p>La distribución normal bidimensional es una extensión de la distribución normal para dos variables. Se caracteriza por dos medias, dos varianzas y una covarianza que describe la relación entre las dos variables.</p>
                                    </li>
                                    <li><b>5.1.6 Intervalos de confianza y pruebas para el coeficiente de correlación:</b>
                                        <p>Los intervalos de confianza para el coeficiente de correlación proporcionan un rango de valores plausibles para el coeficiente de correlación en la población. Las pruebas de hipótesis se utilizan para evaluar si el coeficiente de correlación es significativamente diferente de cero.</p>
                                    </li>
                                    <li><b>5.1.7 Errores de medición:</b>
                                        <p>Los errores de medición se refieren a las diferencias entre los valores observados y los valores verdaderos de una variable. Pueden afectar la precisión y la validez de los resultados de la regresión y la correlación.</p>
                                    </li>
                                </ul>
                            </li>
                        </ul>


                        
</body>

</html>