<!DOCTYPE html>
<html>
<head>
    <link rel="stylesheet"
    href="style.css">
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
  <title>Temario</title>
</head>
<body>
    <center><h1>Tema 1</h1></center>
    <center><h2>Estadistica descriptiva</h2></center>
    
    <img src="https://www.questionpro.com/blog/wp-content/uploads/2021/05/1711-Portada-estadistica-descriptiva.jpg" />

    <!-- Tema 1 -->
    <ul>
        <li><h4>1.1 Conceptos básicos de estadística.</h4>
            <ul>
                <li><b>Definición de Estadística:</b> 
                    La estadística es la ciencia que estudia cómo recopilar, organizar, analizar e interpretar datos para tomar decisiones informadas. Se divide en dos ramas principales:
                    <ul>
                        <li><b>Estadística descriptiva:</b> Se encarga de resumir y describir las características de un conjunto de datos.</li>
                        <li><b>Estadística inferencial:</b> Utiliza una muestra de datos para hacer inferencias o generalizaciones sobre una población más grande.</li>
                    </ul>
                </li>

                <br>

                <li><b>Teoría de Decisión:</b> 
                    La teoría de decisión se enfoca en la toma de decisiones óptimas bajo condiciones de incertidumbre. Involucra la identificación de diferentes alternativas, la evaluación de sus posibles resultados y la selección de la opción que maximiza los beneficios o minimiza los costos.
                    <ul>
                        <li><b>Decisor:</b> Persona o entidad que toma la decisión.</li>
                        <li><b>Alternativas:</b> Opciones disponibles entre las cuales se puede elegir.</li>
                        <li><b>Estados de la naturaleza:</b> Condiciones o eventos que pueden ocurrir y que afectan el resultado de la decisión.</li>
                        <li><b>Pagos o recompensas:</b> Consecuencias asociadas a cada combinación de alternativa y estado de la naturaleza.</li>
                        <li><b>Criterio de decisión:</b> Regla o principio usado para seleccionar la mejor alternativa (por ejemplo, maximización de la utilidad esperada).</li>
                    </ul>
                </li>

                <br>

                <li><b>Población:</b> 
                    En estadística, la población se refiere al conjunto completo de individuos, elementos, o eventos que poseen alguna característica común y sobre la cual se desea realizar inferencias. Puede ser finita (por ejemplo, todos los estudiantes de una escuela) o infinita (por ejemplo, todos los posibles resultados de lanzar un dado).
                </li>

                <br>
                
                <li><b>Muestra Aleatoria:</b> 
                    Una muestra aleatoria es un subconjunto de la población seleccionado de tal manera que cada individuo tiene una probabilidad conocida y no nula de ser incluido. Las muestras aleatorias son fundamentales en estadística porque permiten hacer inferencias sobre la población con un cierto nivel de confianza.
                    <ul>
                        <li><b>Muestreo aleatorio simple:</b> Cada miembro de la población tiene la misma probabilidad de ser seleccionado.</li>
                        <li><b>Muestreo sistemático:</b> Se selecciona cada ésimo individuo de una lista ordenada de la población.</li>
                        <li><b>Muestreo estratificado:</b> La población se divide en subgrupos homogéneos (estratos) y se selecciona una muestra aleatoria de cada estrato.</li>
                        <li><b>Muestreo por conglomerados:</b> La población se divide en grupos heterogéneos (conglomerados) y se selecciona una muestra aleatoria de estos conglomerados.</li>
                    </ul>
                </li>
                <br>

                <li><b>Parámetros Aleatorios:</b> 
                    Los parámetros aleatorios son características numéricas de una población que se desconocen y que se estiman a partir de muestras. Ejemplos de parámetros incluyen:
                    <ul>
                        <li><b>Media (μ):</b> Valor promedio de la población.</li>
                        <li><b>Varianza (σ²):</b> Medida de la dispersión de los valores de la población respecto a la media.</li>
                        <li><b>Proporción (p):</b> Fracción de la población que posee una determinada característica.</li>
                    </ul>
                    Estos parámetros se contrastan con las <b>estadísticas muestrales</b>, que son valores calculados a partir de una muestra y utilizados para estimar los parámetros poblacionales. Por ejemplo, la media muestral se usa para estimar la media poblacional (μ).
                </li>
            </ul>
        </li>
        
        <li><h4>1.2 Descripción de datos.</h4>
            <ul>
                <li><b>Datos agrupados y no agrupados:</b> 
                    <ul>
                        <li><b>Datos no agrupados:</b> Son datos que se presentan en su forma original sin ninguna organización. Por ejemplo, las alturas individuales de un grupo de estudiantes.</li>
                        <li><b>Datos agrupados:</b> Son datos organizados en tablas de frecuencias. Por ejemplo, las alturas de un grupo de estudiantes organizadas en intervalos de altura.</li>
                    </ul>
                </li>

                <br>

                <li><b>Frecuencia de clase:</b> 
                    Es el número de observaciones que caen dentro de un intervalo de clase específico en una distribución de frecuencias.
                </li>
                
                <br>

                <li><b>Frecuencia relativa:</b> 
                    Es la proporción o fracción de observaciones que pertenecen a una clase en particular. Se calcula dividiendo la frecuencia de clase por el número total de observaciones.
                </li>

                <br>

                <li><b>Punto medio:</b> 
                    Es el valor central de un intervalo de clase. Se calcula sumando los límites inferior y superior del intervalo y dividiendo por dos.
                </li>

                <br>

                <li><b>Límites:</b> 
                    Los límites de clase son los valores que marcan el inicio y el final de un intervalo de clase. Existen dos tipos:
                    <ul>
                        <li><b>Límites reales:</b> Incluyen todos los valores posibles dentro del intervalo, considerando cualquier posible valor decimal o fraccionario.</li>
                        <li><b>Límites aparentes:</b> Son los valores que se presentan como los bordes del intervalo y no consideran los decimales o fraccionarios.</li>
                    </ul>
                </li>
            </ul>
        </li>
        

        <li><h4>1.3 Medidas de tendencia central y de dispersión.</h4>
            <ul>
                <li><b>Media aritmética:</b> 
                    Es el promedio de un conjunto de datos y se calcula sumando todos los valores y dividiendo por el número total de observaciones.
                </li>

                <br>

                <li><b>Media geométrica:</b> 
                    Es la raíz enésima del producto de n valores, útil especialmente para datos que representan tasas de crecimiento.
                </li>

                <br>

                <li><b>Media ponderada:</b> 
                    Es similar a la media aritmética pero asignando diferentes pesos a diferentes valores. Se calcula multiplicando cada valor por su peso, sumando estos productos y dividiendo por la suma de los pesos.
                </li>

                <br>

                <li><b>Mediana:</b> 
                    Es el valor que divide un conjunto de datos ordenados en dos partes iguales. Si el número de observaciones es impar, la mediana es el valor central; si es par, es el promedio de los dos valores centrales.
                </li>

                <br>

                <li><b>Moda:</b> 
                    Es el valor o valores que aparecen con mayor frecuencia en un conjunto de datos. Un conjunto de datos puede tener una moda (unimodal), dos modas (bimodal) o más (multimodal).
                </li>

                <br>

                <li><b>Medidas de dispersión:</b> 
                    Las medidas de dispersión describen la variabilidad o dispersión de los datos respecto a la tendencia central.
                    <ul>
                        <li><b>Varianza (σ²):</b> 
                            Es la media de los cuadrados de las desviaciones de los valores respecto a la media. Indica cuánto varían los datos respecto a la media.
                        </li>
                        <li><b>Desviación estándar (σ):</b> 
                            Es la raíz cuadrada de la varianza y proporciona una medida de dispersión en las mismas unidades que los datos originales.
                        </li>
                        <li><b>Desviación media:</b> 
                            Es la media de las desviaciones absolutas respecto a la media.
                        </li>
                        <li><b>Desviación mediana:</b> 
                            Es la mediana de las desviaciones absolutas respecto a la mediana del conjunto de datos.
                        </li>
                        <li><b>Rango:</b> 
                            Es la diferencia entre el valor máximo y el valor mínimo de un conjunto de datos. Proporciona una medida sencilla de la dispersión.
                        </li>
                    </ul>
                </li>
            </ul>
        </li>

        <li><h4>1.4 Parámetros para datos agrupados.</h4>
            <ul>
                <li>Estos parámetros permiten resumir y caracterizar adecuadamente
                    un conjunto de datos cuando estos se presentan de manera agrupada.</li>
            </ul>
        </li>

        <li><h4>1.5 Distribución de frecuencias.</h4>
            <ul>
                <li>La distribución de frecuencias permite analizar la forma, 
                    dispersión y tendencia central de un conjunto de datos, 
                    facilitando su interpretación y comprensión.</li>
            </ul>
        </li>

        <li><h4>1.6 Técnicas de agrupación de datos.</h4>
            <ul>
                <li>Estas técnicas permiten estructurar adecuadamente
                    los datos, facilitando su análisis, visualización e 
                    interpretación estadística.</li>
            </ul>
        </li>

        <li><h4>1.7 Técnicas de muestreo.</h4>
            <ul>
                <li>Estas técnicas permiten obtener muestras representativas de la 
                    población, de acuerdo a los objetivos y características del estudio.
                </li>
            </ul>
        </li>  
    </ul>
    
     
    <!-- Tema 2 -->
    <center><h1>Tema 2</h1></center>
    <center><h2>Fundamentos de la Teoría de Probabilidad.</h2></center>

    <img src="https://www.esan.edu.pe/images/blog/2016/10/10/probabilidades-principal.jpg" />

    <ul>
        <li><h4>2.1 Conceptos básicos de estadística.</h4>
            <ul>
                <li>Las técnicas de conteo son métodos utilizados en combinatoria y probabilidad para contar el número de formas en que se pueden realizar ciertas acciones o formar conjuntos. A continuación, se describen algunas técnicas de conteo fundamentales:</li>

                <br>

                <li><b>2.1.1 Principio aditivo.</b> 
                    El principio aditivo se utiliza cuando se cuenta el número total de elementos en una unión de conjuntos disjuntos. Si tenemos varios conjuntos que no tienen elementos en común, el número total de elementos es la suma de los elementos de cada conjunto.
                </li>

                <br>

                <b>Ejemplo</b> 
                Si hay 3 maneras de elegir un objeto del conjunto A y 4 maneras de elegir un objeto del conjunto B, y A y B son disjuntos, entonces hay 3 + 4 = 7 maneras de elegir un objeto de A o B.
                
                <br>
                <br>

                <li><b> 2.1.2 Principio multiplicativo:</b> 
                    El principio multiplicativo se utiliza cuando se cuenta el número total de formas en que se pueden realizar varias acciones secuenciales. Si una acción se puede realizar de 𝑛 maneras y una segunda acción se puede realizar de 𝑚 maneras, entonces hay 𝑛 × 𝑚 maneras de realizar ambas acciones.
                </li>

                <br>

                <b>Ejemplo</b> 
                Si hay 3 maneras de elegir un primer objeto y 4 maneras de elegir un segundo objeto, entonces hay 3 × 4 = 12 maneras de elegir ambos objetos.
                
                <br>
                <br>

                <li><b>2.1.3 Notación Factorial:</b> 
                    La notación factorial (denotada como 𝑛!) se utiliza para contar el número de maneras en que se pueden ordenar 𝑛 elementos distintos.
                </li>

                <br>

                <b>Formula</b>
                <p>\[n! = n × (n − 1) × (n − 2) × ⋯ × 1\]</p>

                <b>Ejemplo</b>
                <p>\[5! = 5 × 4 × 3 × 2 × 1 = 120\]</p>
                
                <br>
                <br>

                <li><b> 2.1.4 Permutaciones:</b> 
                    Las permutaciones son arreglos ordenados de un conjunto de elementos. El número de permutaciones de 𝑛 elementos es 𝑛!. Si se seleccionan 𝑟 elementos de un conjunto de 𝑛 elementos para formar permutaciones, se utiliza la notación 𝑃(𝑛,𝑟).
                </li>

                <br>

                <b>Formula</b> 
                <p>\[ P(n, r) = \frac{n!}{(n-r)!} \]</p>

                <b>Ejemplo</b> 
                El número de maneras de ordenar 3 elementos de un conjunto de 5 elementos es: \[𝑃(5,3) = \frac{5!}{(5 − 3)!} = \frac{5 × 4 × 3 × 2 × 1} {2 × 1} = 60\]
                
                <br>
                <br>

                <li><b> 2.1.5 Combinaciones:</b> 
                    Las combinaciones son selecciones no ordenadas de elementos de un conjunto. El número de combinaciones de 𝑛 elementos tomados 𝑟 a la vez se denota como 𝐶(𝑛,𝑟) o (𝑛 / 𝑟).
                </li>

                <br>

                <b>Formula</b> 
                <p>\[C(n,r) = \frac{n}{r} = \frac{n!}{r!(n−r)!}\]</p>

                <b>Ejemplo</b> 
                El número de maneras de elegir 3 elementos de un conjunto de 5 elementos es:\[C(5,3) = \frac{5!}{3!(5-3)!} = \frac{5 \times 4 \times 3 \times 2 \times 1}{3 \times 2 \times 1 \times 2 \times 1} = 10\]
                
                <br>
                <br>

                <li><b> 2.1.6 Diagrama de Árbol:</b> 
                    Un diagrama de árbol es una representación gráfica que se utiliza para visualizar y contar el número de resultados posibles de un evento o serie de eventos.
                </li>

                <br>

                <b>Ejemplo</b> 
                Si se lanza una moneda y luego se lanza un dado, un diagrama de árbol puede mostrar todas las combinaciones posibles de resultados (cara/cruz seguido de 1, 2, 3, 4, 5, 6).
                
                <br>
                
                <br>

                <li><b> 2.1.7 Teorema del Binomio:</b> 
                    El teorema del binomio proporciona una fórmula para expandir una potencia de un binomio. Se utiliza en combinatoria para contar combinaciones de elementos con repetición.
                </li> 

                <br>

                <li><h4>2.1 Conceptos básicos de estadística.</h4>
                    <ul>
                        <li>Las técnicas de conteo son métodos utilizados en combinatoria y probabilidad para contar el número de formas en que se pueden realizar ciertas acciones o formar conjuntos. A continuación, se describen algunas técnicas de conteo fundamentales:</li>
                        <ul>
                            <li><strong>Permutaciones</strong>: La cantidad de maneras en que se pueden ordenar un conjunto de objetos.</li>
                            <li><strong>Combinaciones</strong>: La cantidad de maneras en que se pueden seleccionar objetos de un conjunto, sin importar el orden.</li>
                            <li><strong>Principio de la multiplicación</strong>: Si una tarea puede realizarse de \( n \) maneras y otra tarea puede realizarse de \( m \) maneras, entonces ambas tareas pueden realizarse de \( n \times m \) maneras.</li>
                            <li><strong>Principio de la adición</strong>: Si un evento puede ocurrir de \( n \) maneras y otro evento puede ocurrir de \( m \) maneras, y estos eventos no pueden ocurrir simultáneamente, entonces el número total de maneras en que uno de los eventos puede ocurrir es \( n + m \).</li>
                        </ul>
                    </ul>
                </li>
                <li><h4>2.2 Teoría elemental de probabilidad.</h4>
                    <ul>
                        <li>La teoría elemental de probabilidad es una rama de las matemáticas que estudia los fenómenos aleatorios y los eventos inciertos. Sus conceptos básicos incluyen:</li>
                        <ul>
                            <li><strong>Experimento aleatorio</strong>: Un proceso que produce un resultado incierto.</li>
                            <li><strong>Evento</strong>: Un subconjunto de posibles resultados de un experimento aleatorio.</li>
                            <li><strong>Probabilidad</strong>: Una medida cuantitativa de la incertidumbre asociada con un evento.</li>
                        </ul>
                    </ul>
                </li>
                <li><h4>2.3 Probabilidad de Eventos.</h4>
                    <ul>
                        <li><strong>Definición de espacio muestral</strong>: El conjunto de todos los posibles resultados de un experimento aleatorio. Por ejemplo, al lanzar un dado, el espacio muestral es {1, 2, 3, 4, 5, 6}.</li>
                        <li><strong>Definición de evento</strong>: Cualquier subconjunto del espacio muestral. Por ejemplo, obtener un número par al lanzar un dado puede ser el evento {2, 4, 6}.</li>
                        <li><strong>Simbología</strong>:</li>
                        <ul>
                            <li><strong>P(E)</strong>: La probabilidad de que ocurra el evento E.</li>
                            <li><strong>E'</strong>: El complemento de E, que representa todos los resultados en el espacio muestral que no están en E.</li>
                        </ul>
                        <li><strong>Unión e intersección</strong>:</li>
                        <ul>
                            <li><strong>Unión (E ∪ F)</strong>: Un evento que ocurre si ocurre E, F, o ambos.</li>
                            <li><strong>Intersección (E ∩ F)</strong>: Un evento que ocurre si ocurren tanto E como F.</li>
                        </ul>
                        <li><strong>Diagramas de Venn</strong>: Los diagramas de Venn son una herramienta gráfica para representar visualmente la relación entre diferentes eventos en un espacio muestral.</li>
                    </ul>
                </li>
                <li><h4>2.4 Probabilidad con Técnicas de Conteo.</h4>
                    <ul>
                        <li><strong>Axiomas de probabilidad</strong>:</li>
                        <ul>
                            <li>La probabilidad de un evento es un número no negativo: \( P(E) \geq 0 \).</li>
                            <li>La probabilidad del espacio muestral completo es 1: \( P(S) = 1 \).</li>
                            <li>Si dos eventos E y F son mutuamente excluyentes (es decir, \( E \cap F = \emptyset \)), entonces \( P(E \cup F) = P(E) + P(F) \).</li>
                        </ul>
                        <li><strong>Teoremas de probabilidad</strong>:</li>
                        <ul>
                            <li>Teorema de la probabilidad total: Si \( \{A_1, A_2, ..., A_n\} \) es una partición del espacio muestral S, entonces \( P(B) = \sum_{i=1}^n P(B \cap A_i) \).</li>
                        </ul>
                    </ul>
                </li>
                <li><h4>2.5 Probabilidad condicional.</h4>
                    <ul>
                        <li><strong>Dependiente e Independiente</strong>:</li>
                        <ul>
                            <li>Probabilidad condicional: La probabilidad de un evento A dado que otro evento B ha ocurrido, denotada como \( P(A|B) \).</li>
                            <li>Eventos dependientes: Dos eventos A y B son dependientes si la ocurrencia de uno afecta la probabilidad del otro.</li>
                            <li>Eventos independientes: Dos eventos A y B son independientes si \( P(A \cap B) = P(A)P(B) \).</li>
                        </ul>
                    </ul>
                </li>
                <li><h4>2.6 Ley multiplicativa.</h4>
                    <ul>
                        <li>La ley multiplicativa para eventos independientes establece que \( P(A \cap B) = P(A)P(B) \).</li>
                    </ul>
                </li>
                <li><h4>2.7 Eventos independientes: Regla de Bayes.</h4>
                    <ul>
                        <li>Regla de Bayes: Una fórmula que describe la probabilidad de un evento, basada en el conocimiento previo de condiciones que podrían estar relacionadas con el evento. Se expresa como:</li>
                        <li>\[ P(A|B) = \frac{P(B|A)P(A)}{P(B)} \]</li>
                        <li>Esta regla es fundamental en la estadística y en muchas aplicaciones de la teoría de probabilidad.</li>
                    </ul>
                </li>
    </ul>


    <!-- Tema 3 -->
    <center><h1>Tema 3</h1></center>
    <center><h2>Variables Aleatorias. </h2></center>

    <img src="https://stats.libretexts.org/@api/deki/files/16945/clipboard_e25dd712df7f29256eedc5b306b1d828d.png" />

    <ul>
        <li><h4>3.1 Variables aleatorias discretas:</h4>
            <ul>
                <li><b>3.1.1 Distribución de probabilidad en forma general:</b>
                    <p>La distribución de probabilidad de una variable aleatoria discreta asigna una probabilidad a cada valor posible de la variable. La suma de todas las probabilidades debe ser igual a 1.</p>
                </li>
                <li><b>3.1.2 Valor esperado:</b>
                    <p>El valor esperado (o esperanza matemática) de una variable aleatoria discreta es la suma de todos los valores posibles de la variable, cada uno multiplicado por su probabilidad correspondiente. Se calcula como \(E(X) = \sum_{i} x_i P(x_i)\).</p>
                </li>
                <li><b>3.1.3 Varianza, desviación estándar:</b>
                    <p>La varianza mide la dispersión de una variable aleatoria respecto a su valor esperado. Se calcula como \(Var(X) = \sum_{i} (x_i - E(X))^2 P(x_i)\). La desviación estándar es la raíz cuadrada de la varianza.</p>
                </li>
                <li><b>3.1.4 Función acumulada:</b>
                    <p>La función de distribución acumulada (FDA) de una variable aleatoria discreta es una función que, para cualquier valor x, da la probabilidad de que la variable aleatoria sea menor o igual a x. Se define como \(F(x) = P(X \leq x)\).</p>
                </li>
            </ul>
        </li>
        <li><h4>3.2 Variables aleatorias continuas:</h4>
            <ul>
                <li><b>3.2.1 Distribución de probabilidad en forma general:</b>
                    <p>La distribución de probabilidad de una variable aleatoria continua se describe mediante una función de densidad de probabilidad (FDP). La probabilidad de que la variable aleatoria tome un valor dentro de un intervalo se obtiene integrando la FDP sobre ese intervalo.</p>
                </li>
                <li><b>3.2.2 Valor esperado:</b>
                    <p>El valor esperado de una variable aleatoria continua se calcula como la integral del producto del valor de la variable y su función de densidad de probabilidad, es decir, \(E(X) = \int_{-\infty}^{\infty} x f(x) \, dx\).</p>
                </li>
                <li><b>3.2.3 Varianza, desviación estándar:</b>
                    <p>La varianza de una variable aleatoria continua se calcula como la integral del cuadrado de la diferencia entre el valor de la variable y el valor esperado, multiplicada por la función de densidad de probabilidad: \(Var(X) = \int_{-\infty}^{\infty} (x - E(X))^2 f(x) \, dx\). La desviación estándar es la raíz cuadrada de la varianza.</p>
                </li>
                <li><b>3.2.4 Función acumulada:</b>
                    <p>La función de distribución acumulada (FDA) de una variable aleatoria continua es la integral de la función de densidad de probabilidad desde menos infinito hasta x: \(F(x) = \int_{-\infty}^{x} f(t) \, dt\).</p>
                </li>
                <li><b>3.2.5 Cálculos de probabilidad:</b>
                    <p>Para calcular la probabilidad de que una variable aleatoria continua caiga dentro de un cierto intervalo \([a, b]\), se integra la función de densidad de probabilidad sobre ese intervalo: \(P(a \leq X \leq b) = \int_{a}^{b} f(x) \, dx\).</p>
                </li>
            </ul>
        </li>
    </ul>


</body>
</html>
